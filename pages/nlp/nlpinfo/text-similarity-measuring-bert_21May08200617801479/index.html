
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    

   <meta charset="utf-8">

<meta name="viewport" content="width=device-width,initial-scale=1">

  <meta name="description" content="使用 BERT 等Transformer模型的句子相似性非常容易实现。我们将了解如何实现（在Python），以及为什么它工作这么好。">


  <link rel="canonical" href="https://geek.digiasset.org/pages/nlp/nlpinfo/text-similarity-measuring-bert_21May08200617801479/">


<link rel="shortcut icon" href="/assets/images/favicon.png">

    
      
        <title>BERT用于计算句子文本相似度 - 广告流程自动化</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.33e2939f.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.ef6f36e2.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../../../../stylesheets/extra.css">
    
    
      <!-- Add custom analytics integration here -->
      
          <!-- Global site tag (gtag.js) - Google Analytics -->
          <script async src="https://www.googletagmanager.com/gtag/js?id=G-HS6FYDNKSV"></script>
          <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-HS6FYDNKSV');
          </script>
      

    
    

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="green" data-md-color-accent="indigo">
  
    
    <script>function __prefix(e){return new URL("../../../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
      <script>var palette=__get("__palette");if(null!==palette&&"object"==typeof palette.color)for(var key in palette.color)document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#BERT用于计算句子文本相似度" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="广告流程自动化" class="md-header__button md-logo" aria-label="广告流程自动化" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            广告流程自动化
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              BERT用于计算句子文本相似度
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="green" data-md-color-accent="indigo" type="radio" name="__palette" id="__palette_1">
          <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_2" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3z"/></svg>
          </label>
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="blue" data-md-color-accent="blue" type="radio" name="__palette" id="__palette_2">
          <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M7 10a2 2 0 0 1 2 2 2 2 0 0 1-2 2 2 2 0 0 1-2-2 2 2 0 0 1 2-2m10-3a5 5 0 0 1 5 5 5 5 0 0 1-5 5H7a5 5 0 0 1-5-5 5 5 0 0 1 5-5h10M7 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3h10a3 3 0 0 0 3-3 3 3 0 0 0-3-3H7z"/></svg>
          </label>
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../.." class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../python/" class="md-tabs__link">
        Python
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../html5/" class="md-tabs__link">
        HTML5/CSS
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../ml/matrix/" class="md-tabs__link">
        机器学习
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../mathbasic/mean-formula-exponential-distribution_21Mar04200956862982/" class="md-tabs__link">
        数学基础
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../nlp/" class="md-tabs__link md-tabs__link--active">
        自然语言处理
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../affiliate/seo_competitor_analyze/" class="md-tabs__link">
        广告程序化
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../affiliate/long-tail-keywords-in-article/" class="md-tabs__link">
        网站SEO优化
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../rpa/tool-reptile-mobile-method-introduction_21Oct26195529728646/" class="md-tabs__link">
        自动化与爬虫
      </a>
    </li>
  

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../../about/" class="md-tabs__link">
      关于
    </a>
  </li>

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="广告流程自动化" class="md-nav__button md-logo" aria-label="广告流程自动化" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    广告流程自动化
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" data-md-state="indeterminate" type="checkbox" id="__nav_2" checked>
      
      <label class="md-nav__link" for="__nav_2">
        Python
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Python" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Python
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/" class="md-nav__link">
        python 基础教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-lexicalstructure/" class="md-nav__link">
        Python 语法结构
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-datatypes/" class="md-nav__link">
        Python 数据类型
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-strings/" class="md-nav__link">
        Python 字符串
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-fstring/" class="md-nav__link">
        Python f 字符串
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-lists/" class="md-nav__link">
        Python 列表
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-dictionaries/" class="md-nav__link">
        Python 字典
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-set/" class="md-nav__link">
        Python 集合
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-map/" class="md-nav__link">
        Python 映射
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-operators/" class="md-nav__link">
        Python 运算符
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-keywords/" class="md-nav__link">
        Python 关键字
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-forloop/" class="md-nav__link">
        Python for 循环
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-itergener/" class="md-nav__link">
        Python 迭代器和生成器
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-listcomprehensions/" class="md-nav__link">
        Python 列表推导式
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-reverse/" class="md-nav__link">
        Python 反转
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-functions/" class="md-nav__link">
        Python 函数
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-regularexpressions/" class="md-nav__link">
        Python 正则表达式
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-oop/" class="md-nav__link">
        Python 面向对象编程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-modules/" class="md-nav__link">
        Python 模块
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-packages/" class="md-nav__link">
        Python 中的软件包
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-exceptions/" class="md-nav__link">
        Python 异常
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-introspection/" class="md-nav__link">
        Python 自省
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-lambda/" class="md-nav__link">
        Python Lambda 函数
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-logging/" class="md-nav__link">
        Python 日志教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-simplejson/" class="md-nav__link">
        Python JSON 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-faker/" class="md-nav__link">
        Python Faker 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-feedparser/" class="md-nav__link">
        Python feedparser 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-bcrypt/" class="md-nav__link">
        Python bcrypt 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-socket/" class="md-nav__link">
        Python 套接字教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-smtplib/" class="md-nav__link">
        Python smtplib 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-yaml/" class="md-nav__link">
        Python YAML 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-hashing/" class="md-nav__link">
        Python 哈希教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-configparser/" class="md-nav__link">
        Python ConfigParser 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-argparse/" class="md-nav__link">
        Python argparse 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-sqlite/" class="md-nav__link">
        Python SQLite 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-cerberus/" class="md-nav__link">
        Python Cerberus 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-pymysql/" class="md-nav__link">
        Python PyMySQL 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-peewee/" class="md-nav__link">
        Python Peewee 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-pydal/" class="md-nav__link">
        Python pyDAL 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-pytest/" class="md-nav__link">
        Python Pytest 单元测试教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-beautifulsoup/" class="md-nav__link">
        BeautifulSoup 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-pyquery/" class="md-nav__link">
        Python pyquery 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-sympy/" class="md-nav__link">
        SymPy 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-pandas/" class="md-nav__link">
        Pandas 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-matplotlib/" class="md-nav__link">
        Matplotlib 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-pillow/" class="md-nav__link">
        Pillow 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-ftp/" class="md-nav__link">
        Python FTP 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-requests/" class="md-nav__link">
        Python Requests 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-arrow/" class="md-nav__link">
        Python Arrow 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-magicmethods/" class="md-nav__link">
        Python 魔术方法
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-run-job-orchestrator/" class="md-nav__link">
        python Uipath Orchestrator Cloud API 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../website-categorization-python/" class="md-nav__link">
        Python 使用 Google NLP API进行网站分类
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/calculate-calculus-newton-iteration-solve-high-order-equations/" class="md-nav__link">
        用python算微积分及牛顿迭代求解高阶方程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/py-setuptools/" class="md-nav__link">
        Python打包分发工具setuptools
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-processing-modules-handy-dandy-da_21Apr13181713428312/" class="md-nav__link">
        用于数据处理的Python工具(Numerizer,Faker,Missingno,emot,Arrow)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/single-line-file-tables-python-extract-c_21Apr21115440307019/" class="md-nav__link">
        用 Python Camelot从 PDF 文件中提取表格
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/ipiprequestsscrapy_downdawn-csdn_21Oct18105139565977/" class="md-nav__link">
        多ip服务器绑定ip发送请求（requests和scrapy）
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" data-md-state="indeterminate" type="checkbox" id="__nav_3" checked>
      
      <label class="md-nav__link" for="__nav_3">
        HTML5/CSS
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="HTML5/CSS" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          HTML5/CSS
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/" class="md-nav__link">
        HTML5 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/html_5_intro/" class="md-nav__link">
        HTML5 简介
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/html-head/" class="md-nav__link">
        HTML5 头部
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/html_5_video/" class="md-nav__link">
        HTML5 视频
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/html-tables/" class="md-nav__link">
        HTML5 表格
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/html-images/" class="md-nav__link">
        HTML5 图像
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/html_5_geolocation/" class="md-nav__link">
        HTML5 地理定位
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/html_5_webworkers/" class="md-nav__link">
        HTML5 Worker
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/thinkphp-template-syntax_21Apr18100959778030/" class="md-nav__link">
        ThinkPHP 模板语法
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" data-md-state="indeterminate" type="checkbox" id="__nav_4" checked>
      
      <label class="md-nav__link" for="__nav_4">
        机器学习
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="机器学习" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          机器学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../ml/matrix/" class="md-nav__link">
        机器学习与矩阵,numpy,sklearn等工具
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../ml/sklearn/python-tsne4dimensional-reduction/" class="md-nav__link">
        Python – 如何使用 t-SNE 進行降維
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../ml/basic/eigenvalue-singular-value-decomposition-pca/" class="md-nav__link">
        特征值分解、奇异值分解、PCA概念
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../ml/numpy/numpy-matrix-calculation-module-linalg/" class="md-nav__link">
        Numpy中矩阵计算模块linalg的常用函数
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/function-relu-silent-moon-cold-gelu_-sof_21Mar05214438987767/" class="md-nav__link">
        深度学习的激活函数
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../ml/sklearn/training-speeding-scikit-learn-model_21Mar06152857982617/" class="md-nav__link">
        加快Scikit-Learn训练
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../ml/sklearn/throw-selection-data-away-feature-accura_21Apr21145323697988/" class="md-nav__link">
        特征选择,如何丢掉95%的数据并获得95%的准确率
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../ml/pandas/speed-pandas-line-couple-significantly-c_21May12202229315527/" class="md-nav__link">
        用几行代码显著加快pandas速度的6种方法
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" data-md-state="indeterminate" type="checkbox" id="__nav_5" checked>
      
      <label class="md-nav__link" for="__nav_5">
        数学基础
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="数学基础" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          数学基础
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/mean-formula-exponential-distribution_21Mar04200956862982/" class="md-nav__link">
        指数分布公式的含义
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/mathematical-lesson-layout-latex-formula_21Mar05193828436946/" class="md-nav__link">
        LaTeX 数学公式排版
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/statistical-python-probability-distribut_21Mar05202631292241/" class="md-nav__link">
        常见概率统计分布及Python实现
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/correlation-co-variances-variance-coeffi_21Mar07115144053588/" class="md-nav__link">
        期望值、方差、协方差、相关系数
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/explain-_softmax_21Mar10194153839999/" class="md-nav__link">
        softmax详解
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/least-squares-polynomial-curve-fitting-python/" class="md-nav__link">
        最小二乘法多项式曲线拟合及其python实现
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/loss-function-entropy-cross_21Mar15132523114094/" class="md-nav__link">
        损失函数 - 交叉熵损失函数
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/vector-measurement-feature-distance_21Mar17192854214137/" class="md-nav__link">
        向量的距离度量
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/whitening-deviation-variance-standard-se_21Mar17204632155755/" class="md-nav__link">
        协方差、PCA、样本中心化，白化、方差、标准差、BN
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/variance-sample-cost-reconstruction-mini_21Mar17213251482233/" class="md-nav__link">
        降维基础知识（样本均值、样本方差、中心矩阵）与PCA
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/principle-judgment-analysis-linear-summa_21Mar18175822435322/" class="md-nav__link">
        如何画lda投影结果_线性判别分析（LDA）原理总结
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/translation-matrix-interpretation-geomet_21Mar21114422593344/" class="md-nav__link">
        协方差矩阵的几何解释
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/subspace-matrix-four-connection_21Apr04201538274672/" class="md-nav__link">
        从sympy求最简形矩阵到矩阵的四个子空间及其联系
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/understanding-convolutions_21Apr05213206391248/" class="md-nav__link">
        了解卷积
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/within-vector-significance-product-geome_21Apr08174255708682/" class="md-nav__link">
        向量内积外积的几何意义
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/learning-function-deep-csdn-common-blog-_21Nov09082415645481/" class="md-nav__link">
        深度学习最常用的10个激活函数
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" checked>
      
      <label class="md-nav__link" for="__nav_6">
        自然语言处理
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="自然语言处理" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          自然语言处理
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/" class="md-nav__link">
        自然语言处理
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../nlp-new-entry/" class="md-nav__link">
        NLP 新手上路
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../nlp-hanlp-dictionary/" class="md-nav__link">
        NLP HanNLP 词典分词
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../ml-precision-recall/" class="md-nav__link">
        评价指标：准确率(Precision)、召回率(Recall)、F值(F-Measure)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../keywords_extract/" class="md-nav__link">
        文本关键词提取
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../topicextract/" class="md-nav__link">
        用Python从海量文本抽取主题
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../nlp-tookits/" class="md-nav__link">
        nlp常用工具集
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../hands-on-guide-to-pattern/" class="md-nav__link">
        NLP pattern库 hands on
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../text-summarization-pretrained-ncoders/" class="md-nav__link">
        基于预训练模型的文本摘要
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../server-less-textsummary-keywords-extract/" class="md-nav__link">
        Serverless 实战：如何结合 NLP 实现文本摘要和关键词提取?
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../opensource-projects-2020list/" class="md-nav__link">
        开源项目，涵盖 11 类 AI 学习框架、平台
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../nltk-basic/" class="md-nav__link">
        自然语言处理工具包之NLTK
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../information-extract-basedon-rule-search-engin/" class="md-nav__link">
        基于规则的信息提取，搜索引擎如何检索结果：spaCy简介
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../bert-text-summarizer-chinese/" class="md-nav__link">
        bert-extractive-summarizer 中文文章的抽取式摘要
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../cnn-nlp-understand/" class="md-nav__link">
        理解NLP中的CNN卷积神经网络
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../nlp-dependency-parsing/" class="md-nav__link">
        依存分析与依存树 dependency parse
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../keywords-auto-extract/" class="md-nav__link">
        关键词与文章相关性, 关键词自动标注与提取
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../website-categorization-python/" class="md-nav__link">
        Python 使用 Google NLP API进行网站分类
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../automated-web-crawling/" class="md-nav__link">
        使用 AI 自动执行 Web 爬网
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../classification-of-websites-by-machine-learning/" class="md-nav__link">
        通过机器学习对网站进行分类
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../textrank-pagerank-algorithmus/" class="md-nav__link">
        TextRank算法简述
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../extract-keywords-nltk-textrank/" class="md-nav__link">
        NLTK TextRank实现英文关键词提取
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../extract-keywords-using-spacy-fuzzywuzzy/" class="md-nav__link">
        使用 Spacy和 FuzzyWuzzy 构建关键字提取API
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../cosine-similarity-algorithm2calculate-text-similarity/" class="md-nav__link">
        使用余弦相似度算法计算文本相似度
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../word-sentence-embed-best-technique-count_21Mar06141722360993/" class="md-nav__link">
        细数2018年最好的词嵌入和句嵌入技术
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../text-start-multiclass-finish-classificat_21Mar06184345839969/" class="md-nav__link">
        从头开始多标签文本分类
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../training-text-model-classification-bert_21Mar13104632238439/" class="md-nav__link">
        没有模型训练情况下用BERT做文本分类
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../text-feature-engineering-analysis_21Mar13141607854162/" class="md-nav__link">
        用 NLP 做文本分析和特征工程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../using-similarity-sentence-bert-word2vec-_21Apr13202631442339/" class="md-nav__link">
        如何使用 BERT 和 Word2Vec 计算句子相似性
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          BERT用于计算句子文本相似度
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        BERT用于计算句子文本相似度
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#代码" class="md-nav__link">
    代码
  </a>
  
    <nav class="md-nav" aria-label="代码">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#简单---句子Transformers" class="md-nav__link">
    简单 - 句子Transformers
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#Transformers和PyTorch" class="md-nav__link">
    Transformers和PyTorch
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../topic-modeling-interactive-bertopic_21Apr27173610787396/" class="md-nav__link">
        用BERTopic进行交互式主题建模
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../structured-data-processing-practice20211007/" class="md-nav__link">
        结构化数据提取实践
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../summary-long-extract-bert-article_21Oct23115502660035/" class="md-nav__link">
        BERT时代下的摘要提取长文总结
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../nlpex/csdn-blog-_nlp-summary_miner_zhu-summary_21Oct23175443667734/" class="md-nav__link">
        NLP之文章摘要
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../nlpex/gentle-introduction-to-text-summarization_ml/" class="md-nav__link">
        基于词频计算句子权重的文本自动摘要
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../nlpex/text-task-summarize-incomplete-auto-summ_21Oct24165632331849/" class="md-nav__link">
        文本自动摘要任务的“不完全”心得总结
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../nlpex/topic-entity-model-name-recognition-base_21Oct24174759876009/" class="md-nav__link">
        基于主题模型和命名实体识别的自动摘要方法
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../word-vector-one-hotsvdnnlmword2vecglove_21Oct24183706851403/" class="md-nav__link">
        词向量(one-hot/SVD/NNLM/Word2Vec/GloVe)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../nlpex/practical-guide-generative-examples_21Oct25174535026003/" class="md-nav__link">
        NLP文本摘要实操 - 具有生成示例的实用指南
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" data-md-state="indeterminate" type="checkbox" id="__nav_7" checked>
      
      <label class="md-nav__link" for="__nav_7">
        广告程序化
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="广告程序化" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          广告程序化
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/seo_competitor_analyze/" class="md-nav__link">
        围绕SEO开展竞争对手分析
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/select-products-from-hottrend/" class="md-nav__link">
        Shopify独立站的几套选品方法
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/semantic-search/" class="md-nav__link">
        什么是语义搜索？它是如何影响SEO的
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/submit-website-to-search-engines/" class="md-nav__link">
        如何把网站提交给搜索引擎
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/meta-description/" class="md-nav__link">
        如何编写完美的元描述
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/keywords-opportunities-with-google-trends-ahrefs/" class="md-nav__link">
        使用 Google Trend、Python 和 Ahrefs 查找关键字商机
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/sitemaps-to-be-crawled-with-python/" class="md-nav__link">
        动态网站使用 Python 向 Google 自动提交站点地图
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/facebook-scraping-and-sentiment-analysis-with-python/" class="md-nav__link">
        使用 Python 进行 Facebook 抓取和情绪分析
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/instagram-scraping-and-sentiment-analysis-with-python/" class="md-nav__link">
        Instagram 爬虫
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/find-search-volume-ceiling-for-keyword-categories/" class="md-nav__link">
        使用 Python 查找关键字类别的搜索量上限
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/visualizing-products-amazon_21Mar06142625123432/" class="md-nav__link">
        可视化 100，000 亚马逊产品
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/text-simhash-good-re-process-deep_21Apr03114628313403/" class="md-nav__link">
        使用SimHash进行海量文本去重流程
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_8" data-md-state="indeterminate" type="checkbox" id="__nav_8" checked>
      
      <label class="md-nav__link" for="__nav_8">
        网站SEO优化
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="网站SEO优化" data-md-level="1">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          网站SEO优化
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/long-tail-keywords-in-article/" class="md-nav__link">
        长尾词优化入网页
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/keyword-difficulty/" class="md-nav__link">
        关键词难度：如何确认你在 Google 获得排名的机会
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/how-to-get-on-the-first-page-of-google/" class="md-nav__link">
        如何让网站排名进入谷歌首页
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/amazon-affiliate-marketing/" class="md-nav__link">
        如何搭建一个成功的亚马逊联盟网站
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/seo-backlink-website-directories/" class="md-nav__link">
        SEO之网站分类目录外链推广工具, 高质量外链来源和技巧
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/how-to-analyze-pages-to-generate-content/" class="md-nav__link">
        抓了10万个头条数据，分析了1万爆文，写出了10万阅读量的内容
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/how-to-start-seo/" class="md-nav__link">
        SEO每日流量如何从0到10000
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/use-python-to-get-keywords/" class="md-nav__link">
        Python与SEO 词库完整指南
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/use-python-to-get-keywords2/" class="md-nav__link">
        Python百度下拉框关键词采集
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/adsense/" class="md-nav__link">
        hexo个人next主题博客接入谷歌广告
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9" data-md-state="indeterminate" type="checkbox" id="__nav_9" checked>
      
      <label class="md-nav__link" for="__nav_9">
        自动化与爬虫
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="自动化与爬虫" data-md-level="1">
        <label class="md-nav__title" for="__nav_9">
          <span class="md-nav__icon md-icon"></span>
          自动化与爬虫
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../rpa/tool-reptile-mobile-method-introduction_21Oct26195529728646/" class="md-nav__link">
        移动端爬虫工具与方法介绍
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../about/" class="md-nav__link">
        关于
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="BERT用于计算句子文本相似度">BERT用于计算句子文本相似度<a class="headerlink" href="#BERT用于计算句子文本相似度" title="Permanent link">&para;</a></h1>
<p>这篇文章将是关于BERT和序列相似性的!
NLP的很大一部分是依靠高维空间的相似性。通常情况下，NLP解决方案将一些文本处理以创建一个代表所述文本的大矢量/数组 - 然后执行几个转换。
这是一个高维的魔法。句子相似性是一个最明显的例子，说明了高维魔法可以有多强大。</p>
<p>其逻辑是这样的:
- 取一个句子，把它转换成一个矢量。
- 拿出许多其他的句子，并把它们转换成向量。
- 找出它们之间距离最小（欧几里得）或角度最小（余弦相似度）的句子--<a href="https://towardsdatascience.com/similarity-metrics-in-nlp-acc0777e234c">这里</a>有更多介绍。
- 我们现在有了一个衡量句子之间语义相似性的方法--很简单！在高层次上，没有什么其他的东西。</p>
<p>在高层次上，没有什么其他的东西了。但是，我们当然想更详细地了解正在发生的事情，并在Python中实现它！</p>
<p><strong>为什么BERT有用</strong></p>
<p>正如我们已经提到的，BERT是NLP的MVP。这其中很大一部分归功于BERT将词语的含义嵌入到密集向量中的能力。
我们称其为密集向量，因为向量中的每个值都有一个值，并且有成为该值的原因--这与稀疏向量相反，例如 one-hot 编码向量，其中大多数值为0。
BERT很擅长创建这些密集向量，每个编码器层（有几个）都会输出一组密集向量。</p>
<p><img src='images/p01.png' title="p01.png" alt='句子相似性' /></p>
<p>对于BERT基础，这将是一个包含768的向量。这768个值包含我们对单个标记的数字表示--我们可以将其作为上下文词嵌入。</p>
<p>因为每个符号都有一个这样的向量（由每个编码器输出），所以我们实际上看到的是一个大小为768的张量，即符号的数量。</p>
<p>我们可以利用这些张量--并对它们进行转换，以创建输入序列的语义表示。然后，我们可以采取我们的相似度量，计算不同序列之间各自的相似度。</p>
<p>最简单和最常见的提取的张量是<code>last_hidden_state</code>张量--它是由BERT模型方便地输出的。</p>
<p>当然，这是一个相当大的张量--在512x768--我们希望有一个矢量来应用我们的相似性措施。</p>
<p>要做到这一点，我们需要将我们的<code>last_hidden_states</code>张量转换为768维的向量。</p>
<p><strong>创建矢量</strong></p>
<p>为了将<code>last_hidden_states</code>张量转换为我们的向量--我们使用了一个平均池操作。</p>
<p>这512个标记中的每一个都有各自的768个值。这个池化操作将采取所有标记嵌入的平均值，并将它们压缩到一个单一的768向量空间中--创建一个 "句子向量"。同时，我们不能只取平均激活的原样。我们需要考虑空的填充标记（我们不应该包括这些标记）。</p>
<h2 id="代码">代码<a class="headerlink" href="#代码" title="Permanent link">&para;</a></h2>
<p>这在很大程度上取决于这个过程背后的理论和逻辑——但我们如何在现实中应用这一点呢？</p>
<p>我们将概述两种方法-简单的方法和稍微复杂的方式。</p>
<h3 id="简单---句子Transformers">简单 - 句子Transformers<a class="headerlink" href="#简单---句子Transformers" title="Permanent link">&para;</a></h3>
<p>我们实现我们刚刚覆盖的所有内容的最简单方法是通过 <code>sentence-transformers</code> 库-它将此过程的大部分内容包装成几行代码。</p>
<p>首先，我们使用句子Transformer <code>pip install sentence-transformers</code> 安装。
这个库在幕后使用 HuggingFace 的Transformer， 所以我们实际上可以 <a href="https://huggingface.co/sentence-transformers">在这里</a>找到句子Transformer模型。</p>
<p><a href="https://youtu.be/Ey81KfQ3PQU"><img alt="在Python中使用句子Transformers的计算句子相似性" src="images/p02.jpg" /></a></p>
<p>我们将利用这个 <code>[bert-base-nli-mean-tokens](https://huggingface.co/sentence-transformers/bert-base-nli-mean-tokens)</code> 模型——它实现了我们迄今为止讨论过的逻辑。</p>
<p>(它也使用128个输入标记，而不是512个)。</p>
<p>让我们创建一些句子，初始化我们的模型，并编码句子：</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Three years later, the coffin was still full of Jello.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;The person box was packed with jelly many dozens of months later.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;He found a leprechaun in his walnut shell.&quot;</span>
<span class="p">]</span>

<span class="c1"># Initialize our model:</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;bert-base-nli-mean-tokens&#39;</span><span class="p">)</span>

<span class="c1"># HBox(children=(HTML(value=&#39;&#39;), FloatProgress(value=0.0, max=405234788.0), HTML(value=&#39;&#39;)))</span>
<span class="c1"># Encode the sentences:</span>
<span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
<span class="n">sentence_embeddings</span><span class="o">.</span><span class="n">shape</span>

<span class="c1">## Out[5]: (4, 768)</span>
</code></pre></div>
</td></tr></table>
<p>太好了，我们现在有四个句子嵌入-每个包含768值。</p>
<p>现在，我们要做的是采取这些嵌入，并找到每个之间的舒适相似性。因此，对于句子0：</p>
<blockquote>
<p><code>Three years later, the coffin was still full of Jello.</code></p>
</blockquote>
<p>我们可以用以下方式找到最相似的句子:</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>

<span class="c1"># Let&#39;s calculate cosine similarity for sentence 0:</span>
<span class="n">cosine_similarity</span><span class="p">(</span>
    <span class="p">[</span><span class="n">sentence_embeddings</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
    <span class="n">sentence_embeddings</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="p">)</span>
<span class="c1">## Out[14]: array([[0.33088642, 0.7218851 , 0.55473834]], dtype=float32)</span>
</code></pre></div>
</td></tr></table>
<p>这些相似翻译为：</p>
<table>
<thead>
<tr>
<th>Index</th>
<th>句子</th>
<th>相似性</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go."</td>
<td>0.3309</td>
</tr>
<tr>
<td>2</td>
<td>"The person box was packed with jelly many dozens of months later."</td>
<td>0.7219</td>
</tr>
<tr>
<td>3</td>
<td>"He found a leprechaun in his walnut shell."</td>
<td>0.5547</td>
</tr>
</tbody>
</table>
<p>现在，这是一个更容易--更抽象的方法。七行代码来比较我们的句子。</p>
<h3 id="Transformers和PyTorch">Transformers和PyTorch<a class="headerlink" href="#Transformers和PyTorch" title="Permanent link">&para;</a></h3>
<p>在进入第二种方法之前，值得注意的是，它与第一种方法所做的事情是一样的--但要低一个层次。</p>
<p>通过这种方法，我们需要对<code>last_hidden_state</code>进行自己的转换，以创建句子嵌入。为此，我们进行了平均池化(mean pooling)操作。</p>
<p><a href="https://youtu.be/jVPd7lEvjtg"><img alt="在Python中使用句子Transformers的计算句子相似性" src="images/p03.jpg" /></a> </p>
<p>此外，在 mean pooling 操作之前，我们需要创建<code>last_hidden_state</code>，我们这样做：</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModel</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># First we initialize our model and tokenizer:</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;sentence-transformers/bert-base-nli-mean-tokens&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;sentence-transformers/bert-base-nli-mean-tokens&#39;</span><span class="p">)</span>

<span class="c1"># Then we tokenize the sentences just as before:</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Three years later, the coffin was still full of Jello.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;The person box was packed with jelly many dozens of months later.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;He found a leprechaun in his walnut shell.&quot;</span>
<span class="p">]</span>

<span class="c1"># initialize dictionary to store tokenized sentences</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;input_ids&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
    <span class="c1"># encode each sentence and append to dictionary</span>
    <span class="n">new_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode_plus</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                                       <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span>
                                       <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;pt&#39;</span><span class="p">)</span>
    <span class="n">tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># reformat list of tensors into single tensor</span>
<span class="n">tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">])</span>
<span class="n">tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>

<span class="c1"># We process these tokens through our model:</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">tokens</span><span class="p">)</span>
<span class="n">outputs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>

<span class="c1">## Out[4]: odict_keys([&#39;last_hidden_state&#39;, &#39;pooler_output&#39;])</span>

<span class="c1"># The dense vector representations of our text are contained within the outputs &#39;last_hidden_state&#39; tensor, which we access like so:</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>
<span class="n">embeddings</span>

<span class="n">embeddings</span><span class="o">.</span><span class="n">shape</span>
<span class="c1">## Out[6]: torch.Size([4, 128, 768])</span>
</code></pre></div>
</td></tr></table>
<p>在我们生成了密集的向量后 <code>embeddings</code> ，我们需要执行平均池化操作，以创建单个矢量编码（ <strong>句子嵌入</strong> ）。</p>
<p>为了进行这种平均池化操作，我们将需要把我们的<code>embeddings</code>张量中的每个值都乘以其各自的<code>attention_mask</code>值--这样我们就可以忽略非真实的标记。</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="c1"># To perform this operation, we first resize our attention_mask tensor:</span>
<span class="n">attention_mask</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span>
<span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span>
<span class="c1">## Out[7]: torch.Size([4, 128])</span>

<span class="n">mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">())</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">mask</span><span class="o">.</span><span class="n">shape</span>
<span class="c1">## Out[8]: torch.Size([4, 128, 768])</span>

<span class="n">mask</span>

<span class="c1">#Each vector above represents a single token attention mask - each token now has a vector of size 768 representing it&#39;s attention_mask status. Then we multiply the two tensors to apply the attention mask:</span>
<span class="n">masked_embeddings</span> <span class="o">=</span> <span class="n">embeddings</span> <span class="o">*</span> <span class="n">mask</span>
<span class="n">masked_embeddings</span><span class="o">.</span><span class="n">shape</span>

<span class="c1">## Out[11]: torch.Size([4, 128, 768])</span>

<span class="n">masked_embeddings</span>

<span class="c1"># Then we sum the remained of the embeddings along axis 1:</span>
<span class="n">summed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">masked_embeddings</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">summed</span><span class="o">.</span><span class="n">shape</span>
<span class="c1">## Out[13]: torch.Size([4, 768])</span>

<span class="c1"># Then sum the number of values that must be given attention in each position of the tensor:</span>
<span class="n">summed_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span>
<span class="n">summed_mask</span><span class="o">.</span><span class="n">shape</span>
<span class="c1">## Out[14]: torch.Size([4, 768])</span>

<span class="n">summed_mask</span>

<span class="c1"># Finally, we calculate the mean as the sum of the embedding activations summed divided by the number of values that should be given attention in each position summed_mask:</span>

<span class="n">mean_pooled</span> <span class="o">=</span> <span class="n">summed</span> <span class="o">/</span> <span class="n">summed_mask</span>
<span class="n">mean_pooled</span>
</code></pre></div>
</td></tr></table>
<p>一旦我们有了密集向量，我们就可以计算每个向量之间的余弦相似度--这与我们之前使用的逻辑相同:</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>

<span class="c1">#Let&#39;s calculate cosine similarity for sentence 0:</span>
<span class="c1"># convert from PyTorch tensor to numpy array</span>
<span class="n">mean_pooled</span> <span class="o">=</span> <span class="n">mean_pooled</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="c1"># calculate</span>
<span class="n">cosine_similarity</span><span class="p">(</span>
    <span class="p">[</span><span class="n">mean_pooled</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
    <span class="n">mean_pooled</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="p">)</span>
<span class="c1">## Out[22]: array([[0.33088905, 0.7219259 , 0.55483633]], dtype=float32)</span>
</code></pre></div>
</td></tr></table>
<table>
<thead>
<tr>
<th>Index</th>
<th>Sentence</th>
<th>Similarity</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go."</td>
<td>0.3309</td>
</tr>
<tr>
<td>2</td>
<td>"The person box was packed with jelly many dozens of months later."</td>
<td>0.7219</td>
</tr>
<tr>
<td>3</td>
<td>"He found a leprechaun in his walnut shell."</td>
<td>0.5548</td>
</tr>
</tbody>
</table>
<p>我们返回几乎相同的结果--唯一的区别是，索引三的余弦相似度从0.5547移到了0.5548--这是由于四舍五入造成的微小差异。</p>
<p>关于使用BERT测量句子的语义相似性的介绍就到此为止--同时使用句子Transformers和一个低级实现使用PyTorch和Transformers。</p>
<p>你可以在<a href="https://github.com/jamescalam/transformers/blob/main/course/similarity/04_sentence_transformers.ipynb">这里</a>和<a href="https://github.com/jamescalam/transformers/blob/main/course/similarity/03_calculating_similarity.ipynb">这里</a>找到两种方法的完整笔记本。</p>
<p>我希望你喜欢这篇文章。如果你有任何问题或建议，请通过<a href="https://twitter.com/jamescalam">Twitter</a>中告诉我。如果你对更多这样的内容感兴趣，我也会在<a href="https://www.youtube.com/c/jamesbriggs">YouTube</a>上发布。</p>
<p>凡本网注明"来源：XXX "的文/图/视频等稿件，本网转载出于传递更多信息之目的，并不意味着赞同其观点或证实其内容的真实性。如涉及作品内容、版权和其它问题，请与本网联系，我们将在第一时间删除内容！ <br />
作者: James Briggs<br />
来源： <a href="https://towardsdatascience.com/bert-for-measuring-text-similarity-eec91c6bf9e1">https://towardsdatascience.com/bert-for-measuring-text-similarity-eec91c6bf9e1</a></p>
                
                  
                
              
              
  <!-- Add custom comment system integration here -->
  
  
  
  
    <h3 id="__comments">评论</h3>
    <!-- 来必力City版安装代码 -->
    <div id="lv-container" data-id="city" data-uid="MTAyMC81MTg1MC8yODMzMQ==">
      <script type="text/javascript">
      (function(d, s) {
          var j, e = d.getElementsByTagName(s)[0];

          if (typeof LivereTower === 'function') { return; }

          j = d.createElement(s);
          j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
          j.async = true;

          e.parentNode.insertBefore(j, e);
      })(document, 'script');
      </script>
    </div>
  <!-- City版安装代码已完成 -->
  

            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../using-similarity-sentence-bert-word2vec-_21Apr13202631442339/" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  上一页
                </span>
                如何使用 BERT 和 Word2Vec 计算句子相似性
              </div>
            </div>
          </a>
        
        
          <a href="../topic-modeling-interactive-bertopic_21Apr27173610787396/" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  下一页
                </span>
                用BERTopic进行交互式主题建模
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright md-footer-copyright-mid">
        
      </div>
      
  <div class="md-footer-social">
    
      
      
        
        
      
      <a href="https://twitter.com/autoadgeek" target="_blank" rel="noopener" title="twitter.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
      </a>
    
      
      
        
        
      
      <a href="https://github.com/autoadgeek" target="_blank" rel="noopener" title="github.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
      </a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tabs", "navigation.instant", "navigation.sections", "navigation.expand", "toc.integrate"], "translations": {"clipboard.copy": "\u590d\u5236", "clipboard.copied": "\u5df2\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}, "search": "../../../../assets/javascripts/workers/search.fe42c31b.min.js", "version": null}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.d892486b.min.js"></script>
      
        <script src="../../../../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>