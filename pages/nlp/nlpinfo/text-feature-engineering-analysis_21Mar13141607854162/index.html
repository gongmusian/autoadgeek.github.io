
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    

   <meta charset="utf-8">

<meta name="viewport" content="width=device-width,initial-scale=1">

  <meta name="description" content="语言检测、文本清洗、长度测量、情感分析、命名-实体识别、N-grams频率、词向量、主题建模。在本文，使用NLP和Python，我将解释如何分析文本数据和提取特征。">


  <link rel="canonical" href="https://geek.digiasset.org/pages/nlp/nlpinfo/text-feature-engineering-analysis_21Mar13141607854162/">


<link rel="shortcut icon" href="/assets/images/favicon.png">

    
      
        <title>用 NLP 做文本分析和特征工程 - 广告流程自动化</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.33e2939f.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.ef6f36e2.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../../../../stylesheets/extra.css">
    
    
      <!-- Add custom analytics integration here -->
      
          <!-- Global site tag (gtag.js) - Google Analytics -->
          <script async src="https://www.googletagmanager.com/gtag/js?id=G-HS6FYDNKSV"></script>
          <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-HS6FYDNKSV');
          </script>
      

    
    

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="green" data-md-color-accent="indigo">
  
    
    <script>function __prefix(e){return new URL("../../../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
      <script>var palette=__get("__palette");if(null!==palette&&"object"==typeof palette.color)for(var key in palette.color)document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#用-NLP-做文本分析和特征工程" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="广告流程自动化" class="md-header__button md-logo" aria-label="广告流程自动化" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            广告流程自动化
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              用 NLP 做文本分析和特征工程
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="green" data-md-color-accent="indigo" type="radio" name="__palette" id="__palette_1">
          <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_2" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3z"/></svg>
          </label>
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="blue" data-md-color-accent="blue" type="radio" name="__palette" id="__palette_2">
          <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M7 10a2 2 0 0 1 2 2 2 2 0 0 1-2 2 2 2 0 0 1-2-2 2 2 0 0 1 2-2m10-3a5 5 0 0 1 5 5 5 5 0 0 1-5 5H7a5 5 0 0 1-5-5 5 5 0 0 1 5-5h10M7 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3h10a3 3 0 0 0 3-3 3 3 0 0 0-3-3H7z"/></svg>
          </label>
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../.." class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../python/" class="md-tabs__link">
        Python
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../html5/" class="md-tabs__link">
        HTML5/CSS
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../ml/matrix/" class="md-tabs__link">
        机器学习
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../mathbasic/mean-formula-exponential-distribution_21Mar04200956862982/" class="md-tabs__link">
        数学基础
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../nlp/" class="md-tabs__link md-tabs__link--active">
        自然语言处理
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../affiliate/seo_competitor_analyze/" class="md-tabs__link">
        广告程序化
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../affiliate/long-tail-keywords-in-article/" class="md-tabs__link">
        网站SEO优化
      </a>
    </li>
  

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../../about/" class="md-tabs__link">
      关于
    </a>
  </li>

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="广告流程自动化" class="md-nav__button md-logo" aria-label="广告流程自动化" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    广告流程自动化
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" data-md-state="indeterminate" type="checkbox" id="__nav_2" checked>
      
      <label class="md-nav__link" for="__nav_2">
        Python
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Python" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Python
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/" class="md-nav__link">
        python 基础教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-lexicalstructure/" class="md-nav__link">
        Python 语法结构
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-datatypes/" class="md-nav__link">
        Python 数据类型
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-strings/" class="md-nav__link">
        Python 字符串
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-fstring/" class="md-nav__link">
        Python f 字符串
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-lists/" class="md-nav__link">
        Python 列表
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-dictionaries/" class="md-nav__link">
        Python 字典
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-set/" class="md-nav__link">
        Python 集合
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-map/" class="md-nav__link">
        Python 映射
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-operators/" class="md-nav__link">
        Python 运算符
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-keywords/" class="md-nav__link">
        Python 关键字
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-forloop/" class="md-nav__link">
        Python for 循环
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-itergener/" class="md-nav__link">
        Python 迭代器和生成器
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-listcomprehensions/" class="md-nav__link">
        Python 列表推导式
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-reverse/" class="md-nav__link">
        Python 反转
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-functions/" class="md-nav__link">
        Python 函数
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-regularexpressions/" class="md-nav__link">
        Python 正则表达式
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-oop/" class="md-nav__link">
        Python 面向对象编程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-modules/" class="md-nav__link">
        Python 模块
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-packages/" class="md-nav__link">
        Python 中的软件包
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-exceptions/" class="md-nav__link">
        Python 异常
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-introspection/" class="md-nav__link">
        Python 自省
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-lambda/" class="md-nav__link">
        Python Lambda 函数
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-logging/" class="md-nav__link">
        Python 日志教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-simplejson/" class="md-nav__link">
        Python JSON 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-faker/" class="md-nav__link">
        Python Faker 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-feedparser/" class="md-nav__link">
        Python feedparser 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-bcrypt/" class="md-nav__link">
        Python bcrypt 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-socket/" class="md-nav__link">
        Python 套接字教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-smtplib/" class="md-nav__link">
        Python smtplib 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-yaml/" class="md-nav__link">
        Python YAML 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-hashing/" class="md-nav__link">
        Python 哈希教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-configparser/" class="md-nav__link">
        Python ConfigParser 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-argparse/" class="md-nav__link">
        Python argparse 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-sqlite/" class="md-nav__link">
        Python SQLite 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-cerberus/" class="md-nav__link">
        Python Cerberus 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-pymysql/" class="md-nav__link">
        Python PyMySQL 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-peewee/" class="md-nav__link">
        Python Peewee 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-pydal/" class="md-nav__link">
        Python pyDAL 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-pytest/" class="md-nav__link">
        Python Pytest 单元测试教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-beautifulsoup/" class="md-nav__link">
        BeautifulSoup 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-pyquery/" class="md-nav__link">
        Python pyquery 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-sympy/" class="md-nav__link">
        SymPy 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-pandas/" class="md-nav__link">
        Pandas 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-matplotlib/" class="md-nav__link">
        Matplotlib 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-pillow/" class="md-nav__link">
        Pillow 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-ftp/" class="md-nav__link">
        Python FTP 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-requests/" class="md-nav__link">
        Python Requests 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-arrow/" class="md-nav__link">
        Python Arrow 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-magicmethods/" class="md-nav__link">
        Python 魔术方法
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-run-job-orchestrator/" class="md-nav__link">
        python Uipath Orchestrator Cloud API 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../website-categorization-python/" class="md-nav__link">
        Python 使用 Google NLP API进行网站分类
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/calculate-calculus-newton-iteration-solve-high-order-equations/" class="md-nav__link">
        用python算微积分及牛顿迭代求解高阶方程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/py-setuptools/" class="md-nav__link">
        Python打包分发工具setuptools
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/python-processing-modules-handy-dandy-da_21Apr13181713428312/" class="md-nav__link">
        用于数据处理的Python工具(Numerizer,Faker,Missingno,emot,Arrow)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/pytutorial/single-line-file-tables-python-extract-c_21Apr21115440307019/" class="md-nav__link">
        用 Python Camelot从 PDF 文件中提取表格
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" data-md-state="indeterminate" type="checkbox" id="__nav_3" checked>
      
      <label class="md-nav__link" for="__nav_3">
        HTML5/CSS
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="HTML5/CSS" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          HTML5/CSS
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/" class="md-nav__link">
        HTML5 教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/html_5_intro/" class="md-nav__link">
        HTML5 简介
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/html-head/" class="md-nav__link">
        HTML5 头部
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/html_5_video/" class="md-nav__link">
        HTML5 视频
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/html-tables/" class="md-nav__link">
        HTML5 表格
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/html-images/" class="md-nav__link">
        HTML5 图像
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/html_5_geolocation/" class="md-nav__link">
        HTML5 地理定位
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/html_5_webworkers/" class="md-nav__link">
        HTML5 Worker
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../html5/thinkphp-template-syntax_21Apr18100959778030/" class="md-nav__link">
        ThinkPHP 模板语法
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" data-md-state="indeterminate" type="checkbox" id="__nav_4" checked>
      
      <label class="md-nav__link" for="__nav_4">
        机器学习
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="机器学习" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          机器学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../ml/matrix/" class="md-nav__link">
        机器学习与矩阵,numpy,sklearn等工具
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../ml/sklearn/python-tsne4dimensional-reduction/" class="md-nav__link">
        Python – 如何使用 t-SNE 進行降維
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../ml/basic/eigenvalue-singular-value-decomposition-pca/" class="md-nav__link">
        特征值分解、奇异值分解、PCA概念
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../ml/numpy/numpy-matrix-calculation-module-linalg/" class="md-nav__link">
        Numpy中矩阵计算模块linalg的常用函数
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/function-relu-silent-moon-cold-gelu_-sof_21Mar05214438987767/" class="md-nav__link">
        深度学习的激活函数
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../ml/sklearn/training-speeding-scikit-learn-model_21Mar06152857982617/" class="md-nav__link">
        加快Scikit-Learn训练
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../ml/sklearn/throw-selection-data-away-feature-accura_21Apr21145323697988/" class="md-nav__link">
        特征选择,如何丢掉95%的数据并获得95%的准确率
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" data-md-state="indeterminate" type="checkbox" id="__nav_5" checked>
      
      <label class="md-nav__link" for="__nav_5">
        数学基础
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="数学基础" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          数学基础
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/mean-formula-exponential-distribution_21Mar04200956862982/" class="md-nav__link">
        指数分布公式的含义
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/mathematical-lesson-layout-latex-formula_21Mar05193828436946/" class="md-nav__link">
        LaTeX 数学公式排版
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/statistical-python-probability-distribut_21Mar05202631292241/" class="md-nav__link">
        常见概率统计分布及Python实现
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/correlation-co-variances-variance-coeffi_21Mar07115144053588/" class="md-nav__link">
        期望值、方差、协方差、相关系数
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/explain-_softmax_21Mar10194153839999/" class="md-nav__link">
        softmax详解
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/least-squares-polynomial-curve-fitting-python/" class="md-nav__link">
        最小二乘法多项式曲线拟合及其python实现
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/loss-function-entropy-cross_21Mar15132523114094/" class="md-nav__link">
        损失函数 - 交叉熵损失函数
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/vector-measurement-feature-distance_21Mar17192854214137/" class="md-nav__link">
        向量的距离度量
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/whitening-deviation-variance-standard-se_21Mar17204632155755/" class="md-nav__link">
        协方差、PCA、样本中心化，白化、方差、标准差、BN
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/variance-sample-cost-reconstruction-mini_21Mar17213251482233/" class="md-nav__link">
        降维基础知识（样本均值、样本方差、中心矩阵）与PCA
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/principle-judgment-analysis-linear-summa_21Mar18175822435322/" class="md-nav__link">
        如何画lda投影结果_线性判别分析（LDA）原理总结
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/translation-matrix-interpretation-geomet_21Mar21114422593344/" class="md-nav__link">
        协方差矩阵的几何解释
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/subspace-matrix-four-connection_21Apr04201538274672/" class="md-nav__link">
        从sympy求最简形矩阵到矩阵的四个子空间及其联系
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/understanding-convolutions_21Apr05213206391248/" class="md-nav__link">
        了解卷积
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../mathbasic/within-vector-significance-product-geome_21Apr08174255708682/" class="md-nav__link">
        向量内积外积的几何意义
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" checked>
      
      <label class="md-nav__link" for="__nav_6">
        自然语言处理
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="自然语言处理" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          自然语言处理
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/" class="md-nav__link">
        自然语言处理
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../nlp-new-entry/" class="md-nav__link">
        NLP 新手上路
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../nlp-hanlp-dictionary/" class="md-nav__link">
        NLP HanNLP 词典分词
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../ml-precision-recall/" class="md-nav__link">
        评价指标：准确率(Precision)、召回率(Recall)、F值(F-Measure)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../keywords_extract/" class="md-nav__link">
        文本关键词提取
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../topicextract/" class="md-nav__link">
        用Python从海量文本抽取主题
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../nlp-tookits/" class="md-nav__link">
        nlp常用工具集
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../hands-on-guide-to-pattern/" class="md-nav__link">
        NLP pattern库 hands on
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../text-summarization-pretrained-ncoders/" class="md-nav__link">
        基于预训练模型的文本摘要
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../server-less-textsummary-keywords-extract/" class="md-nav__link">
        Serverless 实战：如何结合 NLP 实现文本摘要和关键词提取?
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../opensource-projects-2020list/" class="md-nav__link">
        开源项目，涵盖 11 类 AI 学习框架、平台
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../nltk-basic/" class="md-nav__link">
        自然语言处理工具包之NLTK
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../information-extract-basedon-rule-search-engin/" class="md-nav__link">
        基于规则的信息提取，搜索引擎如何检索结果：spaCy简介
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../bert-text-summarizer-chinese/" class="md-nav__link">
        bert-extractive-summarizer 中文文章的抽取式摘要
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../cnn-nlp-understand/" class="md-nav__link">
        理解NLP中的CNN卷积神经网络
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../nlp-dependency-parsing/" class="md-nav__link">
        依存分析与依存树 dependency parse
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../keywords-auto-extract/" class="md-nav__link">
        关键词与文章相关性, 关键词自动标注与提取
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../website-categorization-python/" class="md-nav__link">
        Python 使用 Google NLP API进行网站分类
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../automated-web-crawling/" class="md-nav__link">
        使用 AI 自动执行 Web 爬网
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../classification-of-websites-by-machine-learning/" class="md-nav__link">
        通过机器学习对网站进行分类
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../textrank-pagerank-algorithmus/" class="md-nav__link">
        TextRank算法简述
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../extract-keywords-nltk-textrank/" class="md-nav__link">
        NLTK TextRank实现英文关键词提取
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../extract-keywords-using-spacy-fuzzywuzzy/" class="md-nav__link">
        使用 Spacy和 FuzzyWuzzy 构建关键字提取API
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../cosine-similarity-algorithm2calculate-text-similarity/" class="md-nav__link">
        使用余弦相似度算法计算文本相似度
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../word-sentence-embed-best-technique-count_21Mar06141722360993/" class="md-nav__link">
        细数2018年最好的词嵌入和句嵌入技术
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../text-start-multiclass-finish-classificat_21Mar06184345839969/" class="md-nav__link">
        从头开始多标签文本分类
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../training-text-model-classification-bert_21Mar13104632238439/" class="md-nav__link">
        没有模型训练情况下用BERT做文本分类
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          用 NLP 做文本分析和特征工程
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        用 NLP 做文本分析和特征工程
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#设置" class="md-nav__link">
    设置
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#语言检测" class="md-nav__link">
    语言检测
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#文本预处理" class="md-nav__link">
    文本预处理
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#长度分析" class="md-nav__link">
    长度分析
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#情绪分析" class="md-nav__link">
    情绪分析
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#命名实体识别-NER" class="md-nav__link">
    命名实体识别 NER
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#词频" class="md-nav__link">
    词频
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#单词向量" class="md-nav__link">
    单词向量
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#主题建模" class="md-nav__link">
    主题建模
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#结论" class="md-nav__link">
    结论
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../using-similarity-sentence-bert-word2vec-_21Apr13202631442339/" class="md-nav__link">
        如何使用 BERT 和 Word2Vec 计算句子相似性
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../text-similarity-measuring-bert_21May08200617801479/" class="md-nav__link">
        BERT用于计算句子文本相似度
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../topic-modeling-interactive-bertopic_21Apr27173610787396/" class="md-nav__link">
        用BERTopic进行交互式主题建模
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" data-md-state="indeterminate" type="checkbox" id="__nav_7" checked>
      
      <label class="md-nav__link" for="__nav_7">
        广告程序化
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="广告程序化" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          广告程序化
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/seo_competitor_analyze/" class="md-nav__link">
        围绕SEO开展竞争对手分析
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/select-products-from-hottrend/" class="md-nav__link">
        Shopify独立站的几套选品方法
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/semantic-search/" class="md-nav__link">
        什么是语义搜索？它是如何影响SEO的
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/submit-website-to-search-engines/" class="md-nav__link">
        如何把网站提交给搜索引擎
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/meta-description/" class="md-nav__link">
        如何编写完美的元描述
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/keywords-opportunities-with-google-trends-ahrefs/" class="md-nav__link">
        使用 Google Trend、Python 和 Ahrefs 查找关键字商机
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/sitemaps-to-be-crawled-with-python/" class="md-nav__link">
        动态网站使用 Python 向 Google 自动提交站点地图
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/facebook-scraping-and-sentiment-analysis-with-python/" class="md-nav__link">
        使用 Python 进行 Facebook 抓取和情绪分析
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/instagram-scraping-and-sentiment-analysis-with-python/" class="md-nav__link">
        Instagram 爬虫
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/find-search-volume-ceiling-for-keyword-categories/" class="md-nav__link">
        使用 Python 查找关键字类别的搜索量上限
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/visualizing-products-amazon_21Mar06142625123432/" class="md-nav__link">
        可视化 100，000 亚马逊产品
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/text-simhash-good-re-process-deep_21Apr03114628313403/" class="md-nav__link">
        使用SimHash进行海量文本去重流程
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_8" data-md-state="indeterminate" type="checkbox" id="__nav_8" checked>
      
      <label class="md-nav__link" for="__nav_8">
        网站SEO优化
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="网站SEO优化" data-md-level="1">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          网站SEO优化
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/long-tail-keywords-in-article/" class="md-nav__link">
        长尾词优化入网页
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/keyword-difficulty/" class="md-nav__link">
        关键词难度：如何确认你在 Google 获得排名的机会
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/how-to-get-on-the-first-page-of-google/" class="md-nav__link">
        如何让网站排名进入谷歌首页
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/amazon-affiliate-marketing/" class="md-nav__link">
        如何搭建一个成功的亚马逊联盟网站
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/seo-backlink-website-directories/" class="md-nav__link">
        SEO之网站分类目录外链推广工具, 高质量外链来源和技巧
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/how-to-analyze-pages-to-generate-content/" class="md-nav__link">
        抓了10万个头条数据，分析了1万爆文，写出了10万阅读量的内容
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/how-to-start-seo/" class="md-nav__link">
        SEO每日流量如何从0到10000
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/use-python-to-get-keywords/" class="md-nav__link">
        Python与SEO 词库完整指南
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/use-python-to-get-keywords2/" class="md-nav__link">
        Python百度下拉框关键词采集
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../../affiliate/adsense/" class="md-nav__link">
        hexo个人next主题博客接入谷歌广告
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../about/" class="md-nav__link">
        关于
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="用-NLP-做文本分析和特征工程">用 NLP 做文本分析和特征工程<a class="headerlink" href="#用-NLP-做文本分析和特征工程" title="Permanent link">&para;</a></h1>
<p>本文使用NLP和Python 解释如何分析文本数据和提取特征。</p>
<p>NLP（Natural Language Processing，自然语言处理）是研究计算机与人类语言之间相互作用的人工智能领域，特别是如何对计算机进行编程，以处理和分析大量的自然语言数据。NLP常被应用于文本数据的分类。文本分类就是根据文本数据的内容给文本数据分配类别的问题。文本分类中最重要的部分是特征工程：从原始文本数据创建机器学习模型的特征的过程。
在本文中，我将解释不同的方法来分析文本并提取可用于建立分类模型的特征。我将介绍一些有用的Python代码，这些代码可以很容易地应用在其他类似的情况下（只需复制、粘贴、运行），并通过每一行代码的注释进行演练，以便您可以复制这个例子（链接到下面的完整代码）。</p>
<p><a href="https://github.com/mdipietro09/DataScience_ArtificialIntelligence_Utils/blob/master/natural_language_processing/example_text_classification.ipynb">Natural Language Processing - Text Classification example</a></p>
<p>我将使用<a href="https://www.kaggle.com/rmisra/news-category-dataset">新闻类别数据集</a>，在该数据集中，你将获得从HuffPost获得的2012年至2018年的新闻标题，并要求你用正确的类别对其进行分类。</p>
<p>具体来说，我将逐步讲解： <br />
- 环境设置：导入包，读取数据。   <br />
- 语言检测：了解哪些自然语言数据。 <br />
- 文本预处理：文本清洗和转换。 <br />
- 长度分析：用不同的指标来衡量。 <br />
- 情感分析：判断一个文本是正面还是负面。 <br />
- 命名-实体识别：用预先定义的类别给文本打上标签，如人名、组织、地点。 <br />
- 词频：找到最重要的n-grams。 <br />
- 词向量：将一个词转化为数字。 <br />
- 主题建模：从语料库中提取主要主题。</p>
<h2 id="设置">设置<a class="headerlink" href="#设置" title="Permanent link">&para;</a></h2>
<p>首先，我需要导入以下库。
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="c1">## for data</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="c1">## for plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">wordcloud</span>
<span class="c1">## for text processing</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="c1">## for language detection</span>
<span class="kn">import</span> <span class="nn">langdetect</span> 
<span class="c1">## for sentiment</span>
<span class="kn">from</span> <span class="nn">textblob</span> <span class="kn">import</span> <span class="n">TextBlob</span>
<span class="c1">## for ner</span>
<span class="kn">import</span> <span class="nn">spacy</span>
<span class="c1">## for vectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">feature_extraction</span><span class="p">,</span> <span class="n">manifold</span>
<span class="c1">## for word embedding</span>
<span class="kn">import</span> <span class="nn">gensim.downloader</span> <span class="k">as</span> <span class="nn">gensim_api</span>
<span class="c1">## for topic modeling</span>
<span class="kn">import</span> <span class="nn">gensim</span>
</code></pre></div>
</td></tr></table>
数据集包含在 json 文件中，因此我将首先将其读入包含 json 包的字典列表，然后将其转换为pandas dataframe。
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">lst_dics</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data.json&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">json_file</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">dic</span> <span class="ow">in</span> <span class="n">json_file</span><span class="p">:</span>
        <span class="n">lst_dics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">dic</span><span class="p">)</span> <span class="p">)</span>
<span class="c1">## print the first one      </span>
<span class="n">lst_dics</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>
</td></tr></table></p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141612371071_1.png' width='1340' height='199' /></p>
<p>原始数据集包含 30 多个类别，但出于本教程的目的，我将使用 3 个子集：娱乐、政治和技术(Entertainment, Politics, Tech)。
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="c1">## create dtf</span>
<span class="n">dtf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">lst_dics</span><span class="p">)</span>
<span class="c1">## filter categories</span>
<span class="n">dtf</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;category&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="s1">&#39;ENTERTAINMENT&#39;</span><span class="p">,</span><span class="s1">&#39;POLITICS&#39;</span><span class="p">,</span><span class="s1">&#39;TECH&#39;</span><span class="p">])</span> <span class="p">][[</span><span class="s2">&quot;category&quot;</span><span class="p">,</span><span class="s2">&quot;headline&quot;</span><span class="p">]]</span>
<span class="c1">## rename columns</span>
<span class="n">dtf</span> <span class="o">=</span> <span class="n">dtf</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;category&quot;</span><span class="p">:</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="s2">&quot;headline&quot;</span><span class="p">:</span><span class="s2">&quot;text&quot;</span><span class="p">})</span>
<span class="c1">## print 5 random rows</span>
<span class="n">dtf</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141612541741_1.png' width='964' height='324' /></p>
<p>为了了解数据集的组成，我将通过用条形图显示标签频率来研究单向分布（只有一个变量的概率分布）。
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">x</span> <span class="o">=</span> <span class="s2">&quot;y&quot;</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">dtf</span><span class="p">[</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span> 
       <span class="s2">&quot;index&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;barh&quot;</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
</td></tr></table></p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141612710476_1.png' width='1023' height='451' /></p>
<p>数据集不平衡：与其他新闻相比，Tech 新闻的比例非常小。这在建模过程中可能会产生问题，再抽样重建数据集可能会有用。</p>
<p>现在，一切都已设置，我将首先清理数据，然后我将从原始文本中提取不同的见解，并将它们添加为数据框架的新列。此新信息可用作分类模型的潜在特征。</p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141612876809_1.png' width='832' height='291' /></p>
<p>我们开始吧，</p>
<h2 id="语言检测">语言检测<a class="headerlink" href="#语言检测" title="Permanent link">&para;</a></h2>
<p>首先，我想确保所有新闻使用相同语言，这可以用langdetect包很容易地实现。为了说明这一点，我将将其用于数据集的第一个新闻标题：
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">txt</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">txt</span><span class="p">,</span> <span class="s2">&quot; --&gt; &quot;</span><span class="p">,</span> <span class="n">langdetect</span><span class="o">.</span><span class="n">detect</span><span class="p">(</span><span class="n">txt</span><span class="p">))</span>
</code></pre></div>
</td></tr></table></p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141613017492_1.png' width='1329' height='55' /></p>
<p>让我们通过添加带有语言信息的列来为整个数据集进行：
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">dtf</span><span class="p">[</span><span class="s1">&#39;lang&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">langdetect</span><span class="o">.</span><span class="n">detect</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> 
                                 <span class="n">x</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="n">dtf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>
</td></tr></table></p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141613178112_1.png' width='955' height='324' /></p>
<p>数据框架现在有一个新的列。使用以前相同的代码，我可以看到有多少不同的语言：</p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141613349842_1.png' width='873' height='445' /></p>
<p>即使有不同的语言，英语也是主要语言。因此，我要用英语过滤新闻。
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">dtf</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;lang&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;en&quot;</span><span class="p">]</span>
</code></pre></div>
</td></tr></table></p>
<h2 id="文本预处理">文本预处理<a class="headerlink" href="#文本预处理" title="Permanent link">&para;</a></h2>
<p>数据预处理是准备原始数据以使其适合机器学习模型的阶段。对于 NLP，包括文本清理、删除停词、原型和词法化。</p>
<p>文本清理步骤因数据类型和所需任务而异。通常，字符串被转换为小写字母，标点符号在文本被标记之前被删除。 分词是将字符串拆分为字符串列表（或"token"）的过程。</p>
<p>让我们再次使用第一个新闻标题作为示例：
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- original ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- cleaning ---&quot;</span><span class="p">)</span>
<span class="n">txt</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[^\w\s]&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- tokenization ---&quot;</span><span class="p">)</span>
<span class="n">txt</span> <span class="o">=</span> <span class="n">txt</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span>
</code></pre></div>
</td></tr></table></p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141613509174_1.png' width='1831' height='205' /></p>
<p>我们是否希望将所有token保留在列表中？事实上，我们删除所有不提供额外信息的词语。在示例中，最重要的词是"song"，因为它可以将任何分类模型指向正确的方向。相比之下，诸如"and"、"for"、"the"之类的词并不有用，因为它们可能出现在数据集中几乎每一个观察序列中。这些都是停词的例子。</p>
<p>我们可以创建一个通用停词列表的英语词汇,<a href="https://www.nltk.org/">NLTK</a>，这是一套库和函数的符号和统计自然语言处理。
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">lst_stopwords</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s2">&quot;english&quot;</span><span class="p">)</span>
<span class="n">lst_stopwords</span>
</code></pre></div>
</td></tr></table></p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141613702284_1.png' width='1924' height='367' /></p>
<p>让我们从第一个新闻标题中删除这些停止词：
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- remove stopwords ---&quot;</span><span class="p">)</span>
<span class="n">txt</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">txt</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">lst_stopwords</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span>
</code></pre></div>
</td></tr></table></p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141613890740_1.png' width='1382' height='63' /></p>
<p>我们需要非常小心删除停词，因为如果你删除错误的token，你可能会失去重要的信息。例如，"will"一词被删除，我们丢失了这个人是Will Smith的信息。考虑到这一点，在删除停词之前对原始文本进行一些手动修改是有用的（例如，将"Will Smith"替换为"Will_Smith"）。</p>
<p>现在，我们拥有了所有有用的token，我们可以应用单词转换。 stem和Lemmatization都产生单词的根形式。不同的是， stem可能不是一个实际的单词，而lemma 是一个实际的语言单词。这些算法均由 NLTK 提供。</p>
<p>继续示例：
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- stemming ---&quot;</span><span class="p">)</span>
<span class="n">ps</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">stem</span><span class="o">.</span><span class="n">porter</span><span class="o">.</span><span class="n">PorterStemmer</span><span class="p">()</span>
<span class="nb">print</span><span class="p">([</span><span class="n">ps</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">txt</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- lemmatisation ---&quot;</span><span class="p">)</span>
<span class="n">lem</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">stem</span><span class="o">.</span><span class="n">wordnet</span><span class="o">.</span><span class="n">WordNetLemmatizer</span><span class="p">()</span>
<span class="nb">print</span><span class="p">([</span><span class="n">lem</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">txt</span><span class="p">])</span>
</code></pre></div>
</td></tr></table></p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141614020276_1.png' width='1338' height='149' /></p>
<p>正如你所看到的，有些词已经改变了："joins"变成了原型"join"，就像"cups"。另一方面，"official"只是随着茎"offici"而改变，这不是一个词，通过删除后缀"-al"而创建。</p>
<p>我将把所有这些预处理步骤放入一个单一的函数中，并将其应用到整个数据集中。
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">Preprocess a string.</span>
<span class="sd">:parameter</span>
<span class="sd">    :param text: string - name of column containing text</span>
<span class="sd">    :param lst_stopwords: list - list of stopwords to remove</span>
<span class="sd">    :param flg_stemm: bool - whether stemming is to be applied</span>
<span class="sd">    :param flg_lemm: bool - whether lemmitisation is to be applied</span>
<span class="sd">:return</span>
<span class="sd">    cleaned text</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="k">def</span> <span class="nf">utils_preprocess_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">flg_stemm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">flg_lemm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">lst_stopwords</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1">## clean (convert to lowercase and remove punctuations and characters and then strip)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[^\w\s]&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>

    <span class="c1">## Tokenize (convert from string to list)</span>
    <span class="n">lst_text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="c1">## remove Stopwords</span>
    <span class="k">if</span> <span class="n">lst_stopwords</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">lst_text</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">lst_text</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> 
                    <span class="n">lst_stopwords</span><span class="p">]</span>

    <span class="c1">## Stemming (remove -ing, -ly, ...)</span>
    <span class="k">if</span> <span class="n">flg_stemm</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">ps</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">stem</span><span class="o">.</span><span class="n">porter</span><span class="o">.</span><span class="n">PorterStemmer</span><span class="p">()</span>
        <span class="n">lst_text</span> <span class="o">=</span> <span class="p">[</span><span class="n">ps</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">lst_text</span><span class="p">]</span>

    <span class="c1">## Lemmatisation (convert the word into root word)</span>
    <span class="k">if</span> <span class="n">flg_lemm</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">lem</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">stem</span><span class="o">.</span><span class="n">wordnet</span><span class="o">.</span><span class="n">WordNetLemmatizer</span><span class="p">()</span>
        <span class="n">lst_text</span> <span class="o">=</span> <span class="p">[</span><span class="n">lem</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">lst_text</span><span class="p">]</span>

    <span class="c1">## back to string from list</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">lst_text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span>
</code></pre></div>
</td></tr></table></p>
<p>请注意，您不应该同时应用stem和lemmatization。在这里，我要使用lemmatization。</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;text_clean&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">utils_preprocess_text</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">flg_stemm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">flg_lemm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">lst_stopwords</span><span class="p">))</span>
</code></pre></div>
</td></tr></table>
<p>和以前一样，我创建了一个新列:</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">dtf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>
</td></tr></table>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141614288845_1.png' width='1538' height='326' /></p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot; --&gt; &quot;</span><span class="p">,</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;text_clean&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div>
</td></tr></table>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141614493246_1.png' width='1910' height='74' /></p>
<h2 id="长度分析">长度分析<a class="headerlink" href="#长度分析" title="Permanent link">&para;</a></h2>
<p>查看文本的长度很重要，因为它是一种简单的计算方法，可以提供大量的见解。例如，也许我们很幸运地发现，一个类别系统地比另一个类别长，长度只是构建模型所需的唯一功能。不幸的是，这不会是这样，因为新闻头条有类似的长度，但它是值得一试。</p>
<p>文本数据有几个长度度量。我会举一些例子：</p>
<ul>
<li><strong>字数</strong> ：计算文本中的token数量（由空格分离）</li>
<li><strong>字符计数</strong> ：将每个token的字符数相总</li>
<li><strong>句子计数</strong> ：计算句子数（按句点分离）</li>
<li><strong>平均单词长度</strong> ：单词长度之和除以单词数（字符计数/单词计数）</li>
<li><strong>平均句子长度</strong> ：句子长度之和除以句子数（字数/句子数）</li>
</ul>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">dtf</span><span class="p">[</span><span class="s1">&#39;word_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)))</span>
<span class="n">dtf</span><span class="p">[</span><span class="s1">&#39;char_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)))</span>
<span class="n">dtf</span><span class="p">[</span><span class="s1">&#39;sentence_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)))</span>
<span class="n">dtf</span><span class="p">[</span><span class="s1">&#39;avg_word_length&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="s1">&#39;char_count&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">dtf</span><span class="p">[</span><span class="s1">&#39;word_count&#39;</span><span class="p">]</span>
<span class="n">dtf</span><span class="p">[</span><span class="s1">&#39;avg_sentence_lenght&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="s1">&#39;word_count&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">dtf</span><span class="p">[</span><span class="s1">&#39;sentence_count&#39;</span><span class="p">]</span>
<span class="n">dtf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>
</td></tr></table>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141614634142_1.png' width='1941' height='605' /></p>
<p>让我们看看我们通常的例子：</p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141614861377_1.png' width='867' height='210' /></p>
<p>这些新变量与目标的分布情况如何？要回答这个问题，我将查看双变量分布（两个变量如何一起移动）。首先，我将整组观测结果分成3个样本（政治、娱乐、技术），然后比较样本的直方图和密度。如果分布不同，则变量是预测性的，因为 3 组具有不同的模式。</p>
<p>例如，让我们看看字符计数是否与目标变量相关：
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s2">&quot;char_count&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dtf</span><span class="p">[</span><span class="n">y</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">():</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">dtf</span><span class="p">[</span><span class="n">dtf</span><span class="p">[</span><span class="n">y</span><span class="p">]</span><span class="o">==</span><span class="n">i</span><span class="p">][</span><span class="n">x</span><span class="p">],</span> <span class="n">hist</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                 <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hist_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;alpha&quot;</span><span class="p">:</span><span class="mf">0.8</span><span class="p">},</span> 
                 <span class="n">axlabel</span><span class="o">=</span><span class="s2">&quot;histogram&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">dtf</span><span class="p">[</span><span class="n">dtf</span><span class="p">[</span><span class="n">y</span><span class="p">]</span><span class="o">==</span><span class="n">i</span><span class="p">][</span><span class="n">x</span><span class="p">],</span> <span class="n">hist</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                 <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;shade&quot;</span><span class="p">:</span><span class="kc">True</span><span class="p">},</span> <span class="n">axlabel</span><span class="o">=</span><span class="s2">&quot;density&quot;</span><span class="p">,</span>   
                 <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">dtf</span><span class="p">[</span><span class="n">y</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
</td></tr></table></p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141615014020_1.png' width='1797' height='668' /></p>
<p>这3个类别的长度分布相似。在这里，密度图是非常有用的，因为样本有不同的大小。</p>
<h2 id="情绪分析">情绪分析<a class="headerlink" href="#情绪分析" title="Permanent link">&para;</a></h2>
<p>情绪分析是文本数据通过数字或类的主观情绪的表示。计算情绪是NLP最艰难的任务之一，因为自然语言充满了模糊性。例如，"This is so bad that it’s good"这句话有不止一个解释。模型可以给"good"一词分配一个积极信号，给"bad"一词分配一个负面信号，从而产生中性情绪。之所以发生这种情况，是因为上下文未知。</p>
<p>最好的方法是训练自己的情绪模型，以正确适应您的数据。当没有足够的时间或数据时，可以使用预先训练的模型，如 Textblob 和 Vader。 <a href="https://textblob.readthedocs.io/en/dev/index.html">Textblob</a>，建立在NLTK之上，是最流行的，它可以分配极性的话，并估计整个文本的情绪作为一个平均。另一方面 <a href="https://github.com/cjhutto/vaderSentiment">Vader</a> Valence意识词典和情绪推理器）是一种基于规则的模型，在社交媒体数据上特别有效。</p>
<p>我用Textblob添加一个情绪特征：</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;text_clean&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> 
                   <span class="n">TextBlob</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">sentiment</span><span class="o">.</span><span class="n">polarity</span><span class="p">)</span>
<span class="n">dtf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>
</td></tr></table>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141615255327_1.png' width='1944' height='689' /></p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot; --&gt; &quot;</span><span class="p">,</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;sentiment&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div>
</td></tr></table>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141615485672_1.png' width='1336' height='36' /></p>
<p>类别和情绪之间是否有模式？</p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141615690740_1.png' width='1803' height='665' /></p>
<p>大多数头条新闻都有中性情绪，除了负面尾巴上偏斜的政治新闻，以及正面尾巴上尖峰的科技新闻。</p>
<h2 id="命名实体识别-NER">命名实体识别 NER<a class="headerlink" href="#命名实体识别-NER" title="Permanent link">&para;</a></h2>
<p>NER<a href="https://en.wikipedia.org/wiki/Named-entity_recognition">命名实体识别</a>是指用预先定义的类别（如人名、组织、地点、时间表达、数量等）标记非结构化文本中提及的命名实体的过程。</p>
<p>训练NER模型非常耗时，因为它需要一个相当丰富的数据集。幸运的是，有人已经为我们做了这项工作。最好的开源NER工具之一是 <a href="https://spacy.io/">SpaCy</a>。它提供了不同的 NLP 模型，能够识别多个类别的实体。</p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141615950176_1.png' width='923' height='1341' />source: <a href="https://spacy.io/api/annotation#section-named-entities">SpaCy</a></p>
<p>我将举一个例子，使用 SpaCy 模型en_core_web_lg（在 Web 数据上训练的英语大模型）在我们的通常标题（原始文本，而不是预处理）：</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="c1">## call model</span>
<span class="n">ner</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;en_core_web_lg&quot;</span><span class="p">)</span>
<span class="c1">## tag text</span>
<span class="n">txt</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">ner</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span>
<span class="c1">## display result</span>
<span class="n">spacy</span><span class="o">.</span><span class="n">displacy</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;ent&quot;</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141616186843_1.png' width='1620' height='70' /></p>
<p>这很酷， 但我们怎样才能把它变成一个有用的功能呢？这就是我要做的：</p>
<ul>
<li>运行数据集中每个文本观察的NER模型，就像我在上一个示例中所做的那样。</li>
<li>
<p>对于每个新闻标题，我将把所有已识别的实体放入一个新的列（命名为"标签"），以及同一实体出现在文本中的次数。在示例中，如下</p>
<div class="codehilite"><pre><span></span><code>```
{ (‘Will Smith’, ‘PERSON’):1,
(‘Diplo’, ‘PERSON’):1,
(‘Nicky Jam’, ‘PERSON’):1,
(“The 2018 World Cup’s”, ‘EVENT’):1 }
```
</code></pre></div>

</li>
<li>
<p>然后，我将为每个标签类别（人员、组织、事件、...）创建一个新列，并计算每个标记类别中已找到的实体的数量。在上面的示例中，特征是  <br />
        <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>tags_PERSON = 3
tags_EVENT = 1
</code></pre></div>
</td></tr></table></p>
</li>
</ul>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="c1">## tag text and exctract tags into a list</span>
<span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;tags&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[(</span><span class="n">tag</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">tag</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span> 
                                <span class="k">for</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">ner</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">ents</span><span class="p">]</span> <span class="p">)</span>
<span class="c1">## utils function to count the element of a list</span>
<span class="k">def</span> <span class="nf">utils_lst_count</span><span class="p">(</span><span class="n">lst</span><span class="p">):</span>
    <span class="n">dic_counter</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">lst</span><span class="p">:</span>
        <span class="n">dic_counter</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">dic_counter</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">OrderedDict</span><span class="p">(</span> 
                     <span class="nb">sorted</span><span class="p">(</span><span class="n">dic_counter</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> 
                     <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">lst_count</span> <span class="o">=</span> <span class="p">[</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span><span class="n">value</span><span class="p">}</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span><span class="n">value</span> <span class="ow">in</span> <span class="n">dic_counter</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="p">]</span>
    <span class="k">return</span> <span class="n">lst_count</span>

<span class="c1">## count tags</span>
<span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;tags&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;tags&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">utils_lst_count</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="c1">## utils function create new column for each tag category</span>
<span class="k">def</span> <span class="nf">utils_ner_features</span><span class="p">(</span><span class="n">lst_dics_tuples</span><span class="p">,</span> <span class="n">tag</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lst_dics_tuples</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">tag_type</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">dic_tuples</span> <span class="ow">in</span> <span class="n">lst_dics_tuples</span><span class="p">:</span>
            <span class="k">for</span> <span class="nb">tuple</span> <span class="ow">in</span> <span class="n">dic_tuples</span><span class="p">:</span>
                <span class="nb">type</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dic_tuples</span><span class="p">[</span><span class="nb">tuple</span><span class="p">]</span>
                <span class="n">tag_type</span> <span class="o">=</span> <span class="n">tag_type</span> <span class="o">+</span> <span class="p">[</span><span class="nb">type</span><span class="p">]</span><span class="o">*</span><span class="n">n</span>
                <span class="n">dic_counter</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tag_type</span><span class="p">:</span>
                    <span class="n">dic_counter</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">dic_counter</span><span class="p">[</span><span class="n">tag</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>

<span class="c1">## extract features</span>
<span class="n">tags_set</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">lst</span> <span class="ow">in</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;tags&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">():</span>
     <span class="k">for</span> <span class="n">dic</span> <span class="ow">in</span> <span class="n">lst</span><span class="p">:</span>
          <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">dic</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
              <span class="n">tags_set</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">tags_set</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">tags_set</span><span class="p">))</span>
<span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">tags_set</span><span class="p">:</span>
     <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;tags_&quot;</span><span class="o">+</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;tags&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> 
                             <span class="n">utils_ner_features</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">feature</span><span class="p">))</span>

<span class="c1">## print result</span>
<span class="n">dtf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>
</td></tr></table>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141616325578_1.png' width='1744' height='959' /></p>
<p>现在，我们可以对标记类型分布进行宏观查看。让我们以 ORG 标签（公司和组织）为例：</p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141616570116_1.png' width='1783' height='689' /></p>
<p>为了深入分析，我们需要拆开我们在上一个代码中创建的列"标签"。让我们为标题类别之一绘制最常见的标签：</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">y</span> <span class="o">=</span> <span class="s2">&quot;ENTERTAINMENT&quot;</span>

<span class="n">tags_list</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span><span class="o">==</span><span class="n">y</span><span class="p">][</span><span class="s2">&quot;tags&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">map_lst</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tags_list</span><span class="p">))</span>
<span class="n">dtf_tags</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">map_lst</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tag&#39;</span><span class="p">,</span><span class="s1">&#39;type&#39;</span><span class="p">])</span>
<span class="n">dtf_tags</span><span class="p">[</span><span class="s2">&quot;count&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">dtf_tags</span> <span class="o">=</span> <span class="n">dtf_tags</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;type&#39;</span><span class="p">,</span>  
                <span class="s1">&#39;tag&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">,</span> 
                 <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Top frequent tags&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;count&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;tag&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;type&quot;</span><span class="p">,</span> 
            <span class="n">data</span><span class="o">=</span><span class="n">dtf_tags</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10</span><span class="p">,:],</span> <span class="n">dodge</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
</td></tr></table>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141616822535_1.png' width='1129' height='390' /></p>
<p>继续使用NER的另一个有用的应用：你还记得当我们从"Will Smith"的名称中删除失去"Will"字样的停止词吗？这个问题的一个有趣的解决方案是将"Will Smith"替换为"Will_Smith"，这样它就不会受到停止词删除的影响。由于要通过数据集中的所有文本来更改名称是不可能的，让我们使用 SpaCy 来实现这一点。如我们所知，SpaCy 可以识别一个人的名字，因此我们可以使用它进行 <strong>名称检测</strong> ，然后修改字符串。</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="c1">## predict wit NER</span>
<span class="n">txt</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">entities</span> <span class="o">=</span> <span class="n">ner</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span><span class="o">.</span><span class="n">ents</span>
<span class="c1">## tag text</span>
<span class="n">tagged_txt</span> <span class="o">=</span> <span class="n">txt</span>
<span class="k">for</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">entities</span><span class="p">:</span>
    <span class="n">tagged_txt</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">tag</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tag</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()),</span> 
                        <span class="n">tagged_txt</span><span class="p">)</span> 
<span class="c1">## show result</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tagged_txt</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141616996422_1.png' width='1183' height='39' /></p>
<h2 id="词频">词频<a class="headerlink" href="#词频" title="Permanent link">&para;</a></h2>
<p>到目前为止，我们已经看到了如何通过分析和处理整个文本来做特征工程。现在，我们将通过计算n-gram频率来研究单个单词的重要性。 <strong>n-gram</strong> 是给定文本示例中 n 项的连续词序列。当 n-gram 的大小为 1 时称为unigram（为 2 时是bigram）。</p>
<p>例如，"I like this article"一词可以分解为：</p>
<ul>
<li>4 unigrams: “I”, “like”, “this”, “article”</li>
<li>3 bigrams: “I like”, “like this”, “this article”</li>
</ul>
<p>我将展示如何计算unigram和bigram频率采取政治新闻的样本。
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">y</span> <span class="o">=</span> <span class="s2">&quot;POLITICS&quot;</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span><span class="o">==</span><span class="n">y</span><span class="p">][</span><span class="s2">&quot;text_clean&quot;</span><span class="p">]</span>
<span class="n">lst_tokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">tokenize</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">corpus</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">sep</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">))</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Most frequent words&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="c1">## unigrams</span>
<span class="n">dic_words_freq</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">FreqDist</span><span class="p">(</span><span class="n">lst_tokens</span><span class="p">)</span>
<span class="n">dtf_uni</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dic_words_freq</span><span class="o">.</span><span class="n">most_common</span><span class="p">(),</span> 
                       <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Word&quot;</span><span class="p">,</span><span class="s2">&quot;Freq&quot;</span><span class="p">])</span>
<span class="n">dtf_uni</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;Word&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">top</span><span class="p">,:]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;Freq&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                  <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;barh&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Unigrams&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
                  <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1">## bigrams</span>
<span class="n">dic_words_freq</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">FreqDist</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">ngrams</span><span class="p">(</span><span class="n">lst_tokens</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">dtf_bi</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dic_words_freq</span><span class="o">.</span><span class="n">most_common</span><span class="p">(),</span> 
                      <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Word&quot;</span><span class="p">,</span><span class="s2">&quot;Freq&quot;</span><span class="p">])</span>
<span class="n">dtf_bi</span><span class="p">[</span><span class="s2">&quot;Word&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dtf_bi</span><span class="p">[</span><span class="s2">&quot;Word&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                   <span class="n">string</span> <span class="k">for</span> <span class="n">string</span> <span class="ow">in</span> <span class="n">x</span><span class="p">)</span> <span class="p">)</span>
<span class="n">dtf_bi</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;Word&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">top</span><span class="p">,:]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;Freq&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                  <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;barh&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Bigrams&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                  <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
</td></tr></table></p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141617128175_1.png' width='1918' height='444' /></p>
<p>如果只有一个类别（即政治新闻中的"Republican"）中出现  n-grams，则这些可以成为新特征。一种更费力的方法是将整个语料库向量化，并将所有单词用作特征（词袋法）。</p>
<p>现在，我将向您展示如何在数据帧中添加单词频率作为特征。我们使用Scikit-learn 的CountVectorizer， Python 中最受欢迎的机器学习库之一。矢量器将文本文档集转换为token计数矩阵。我将举一个例子， 使用3 n-grams: “box office”（娱乐新闻中高频词）， "共和republican" （政治新闻高频词）， "apple" （技术新闻高频词）。
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">lst_words</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;box office&quot;</span><span class="p">,</span> <span class="s2">&quot;republican&quot;</span><span class="p">,</span> <span class="s2">&quot;apple&quot;</span><span class="p">]</span>
<span class="c1">## count</span>
<span class="n">lst_grams</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">))</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">lst_words</span><span class="p">]</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">feature_extraction</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">CountVectorizer</span><span class="p">(</span>
                 <span class="n">vocabulary</span><span class="o">=</span><span class="n">lst_words</span><span class="p">,</span> 
                 <span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">lst_grams</span><span class="p">),</span><span class="nb">max</span><span class="p">(</span><span class="n">lst_grams</span><span class="p">)))</span>
<span class="n">dtf_X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;text_clean&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">todense</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">lst_words</span><span class="p">)</span>
<span class="c1">## add the new features as columns</span>
<span class="n">dtf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">dtf</span><span class="p">,</span> <span class="n">dtf_X</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">dtf</span><span class="o">.</span><span class="n">index</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dtf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>
</td></tr></table></p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141617305234_1.png' width='961' height='333' /></p>
<p>可视化相同信息的好方法是 <strong>词云</strong> ，其中每个标签的频率以字体大小和颜色显示。
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">wc</span> <span class="o">=</span> <span class="n">wordcloud</span><span class="o">.</span><span class="n">WordCloud</span><span class="p">(</span><span class="n">background_color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">max_words</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
                         <span class="n">max_font_size</span><span class="o">=</span><span class="mi">35</span><span class="p">)</span>
<span class="n">wc</span> <span class="o">=</span> <span class="n">wc</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">corpus</span><span class="p">))</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">num</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wc</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
</td></tr></table></p>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141617477142_1.png' width='1085' height='540' /></p>
<h2 id="单词向量">单词向量<a class="headerlink" href="#单词向量" title="Permanent link">&para;</a></h2>
<p>最近，NLP 领域开发了新的语言模型，这些模型依赖于神经网络结构，而不是更传统的 n-gram 模型。这些新技术是一组语言建模和功能学习技术，其中单词被转换成真实数字的载体，因此它们被称为 <strong>词嵌入</strong> 。</p>
<p>词嵌入模型通过构建选定单词之前和之后会出现的token的概率分布，将某个单词映射到矢量。这些模型已经迅速流行起来，因为一旦你有真正的数字，而不是字符串，你可以执行计算。例如，要查找相同上下文的单词，只需计算向量距离即可。</p>
<p>有几个 Python 库与这种模型配合工作。SpaCy是其中之一，但既然我们已经使用它，我将谈论另一个著名的包： <a href="https://radimrehurek.com/gensim/">Gensim</a>。使用现代统计机器学习的无监督主题建模和自然语言处理的开源库。使用Gensim，我将加载一个预先训练的GloVe模型。 <a href="https://nlp.stanford.edu/projects/glove/"> GloVe (Global Vectors)</a> 是一种无人监督的学习算法，用于获取大小为 300 的单词的矢量表示。</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">nlp</span> <span class="o">=</span> <span class="n">gensim_api</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;glove-wiki-gigaword-300&quot;</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p>我们可以使用此对象将单词映射到向量：</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">word</span> <span class="o">=</span> <span class="s2">&quot;love&quot;</span>
<span class="n">nlp</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
</code></pre></div>
</td></tr></table>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141617691209_1.png' width='1155' height='451' /></p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">nlp</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
</td></tr></table>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141617877790_1.png' width='141' height='37' /></p>
<p>现在，让我们看看什么是最接近的单词矢量，或者换句话说，这些词大多出现在类似的上下文中。为了在二维空间中绘制向量图，我需要将维度从 300 减少到 2。我用Scikit-learn的t-SNE(t-distributed Stochastic Neighbor Embedding)做到这一点。t-SNE 是可视化高维数据的工具，可将数据点之间的相似性转换为联合概率。</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="c1">## find closest vectors</span>
<span class="n">labels</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">nlp</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nlp</span><span class="p">[</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="c1">## reduce dimensions</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">manifold</span><span class="o">.</span><span class="n">TSNE</span><span class="p">(</span><span class="n">perplexity</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;pca&#39;</span><span class="p">)</span>
<span class="n">new_values</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">new_values</span><span class="p">:</span>
    <span class="n">x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="c1">## plot</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> 
               <span class="n">textcoords</span><span class="o">=</span><span class="s1">&#39;offset points&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">)</span>
<span class="c1">## add center</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">textcoords</span><span class="o">=</span><span class="s1">&#39;offset points&#39;</span><span class="p">,</span>
    <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141617986946_1.png' width='1240' height='625' /></p>
<h2 id="主题建模">主题建模<a class="headerlink" href="#主题建模" title="Permanent link">&para;</a></h2>
<p>Genism 包专门从事主题建模。主题模型是一种统计模型，用于发现文档集中发生的抽象"主题"。</p>
<p>我将展示如何使用 LDA（延迟 Dirichlet 分配）提取主题：一种生成统计模型，允许未观察的小组解释一组观测结果，从而解释为什么数据的某些部分相似。基本上，文档在潜在主题上以随机混合表示，每个主题的特点是分布于单词。</p>
<p>让我们看看我们可以从技术新闻中提取哪些主题。我需要指定模型必须聚类的主题数，我将尝试使用3个主题：</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">y</span> <span class="o">=</span> <span class="s2">&quot;TECH&quot;</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="n">dtf</span><span class="p">[</span><span class="n">dtf</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span><span class="o">==</span><span class="n">y</span><span class="p">][</span><span class="s2">&quot;text_clean&quot;</span><span class="p">]</span>

<span class="c1">## pre-process corpus</span>
<span class="n">lst_corpus</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">string</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
    <span class="n">lst_words</span> <span class="o">=</span> <span class="n">string</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">lst_grams</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">lst_words</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> 
                     <span class="nb">len</span><span class="p">(</span><span class="n">lst_words</span><span class="p">),</span> <span class="mi">2</span><span class="p">)]</span>
    <span class="n">lst_corpus</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lst_grams</span><span class="p">)</span>
<span class="c1">## map words to an id</span>
<span class="n">id2word</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">corpora</span><span class="o">.</span><span class="n">Dictionary</span><span class="p">(</span><span class="n">lst_corpus</span><span class="p">)</span>
<span class="c1">## create dictionary word:freq</span>
<span class="n">dic_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">id2word</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">lst_corpus</span><span class="p">]</span> 
<span class="c1">## train LDA</span>
<span class="n">lda_model</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">ldamodel</span><span class="o">.</span><span class="n">LdaModel</span><span class="p">(</span><span class="n">corpus</span><span class="o">=</span><span class="n">dic_corpus</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="n">id2word</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span> <span class="n">update_every</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">passes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">per_word_topics</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1">## output</span>
<span class="n">lst_dics</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">lst_tuples</span> <span class="o">=</span> <span class="n">lda_model</span><span class="o">.</span><span class="n">get_topic_terms</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">tupla</span> <span class="ow">in</span> <span class="n">lst_tuples</span><span class="p">:</span>
        <span class="n">lst_dics</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="n">i</span><span class="p">,</span> <span class="s2">&quot;id&quot;</span><span class="p">:</span><span class="n">tupla</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
                         <span class="s2">&quot;word&quot;</span><span class="p">:</span><span class="n">id2word</span><span class="p">[</span><span class="n">tupla</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> 
                         <span class="s2">&quot;weight&quot;</span><span class="p">:</span><span class="n">tupla</span><span class="p">[</span><span class="mi">1</span><span class="p">]})</span>
<span class="n">dtf_topics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">lst_dics</span><span class="p">,</span> 
                         <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;topic&#39;</span><span class="p">,</span><span class="s1">&#39;id&#39;</span><span class="p">,</span><span class="s1">&#39;word&#39;</span><span class="p">,</span><span class="s1">&#39;weight&#39;</span><span class="p">])</span>

<span class="c1">## plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;word&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;topic&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">dtf_topics</span><span class="p">,</span> <span class="n">dodge</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Main Topics&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Word Importance&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
</td></tr></table>
<p><img src='images/text-feature-engineering-analysis_21Mar1_21Mar13141618197070_1.png' title="text-feature-engineering-analysis_21Mar1_21Mar13141618197070_1.png" alt="text-feature-engineering-analysis_21Mar1_21Mar13141618197070_1.png" width='1366' height='875' /></p>
<p>试图在短短3个主题中捕捉6年的内容可能有点困难，但正如我们所看到的，关于苹果公司的一切最终都在同一个主题中。</p>
<h2 id="结论">结论<a class="headerlink" href="#结论" title="Permanent link">&para;</a></h2>
<p>本文是一个教程，以演示 <strong>如何分析文本数据与NLP和提取特征的机器学习模型</strong> 。</p>
<p>我展示了如何检测数据所处于的语言，以及如何预处理和清理文本。然后， 我解释了不同的长度测量， 用 Textblob 做了情绪分析， 我们使用 Spacy 进行命名实体识别。最后，我解释了传统单词频率方法与使用Gensim的现代语言模型之间的区别。</p>
<p>现在，您几乎知道所有 NLP 基础知识，可以开始处理文本数据。</p>
<p>凡本网注明"来源：XXX "的文/图/视频等稿件，本网转载出于传递更多信息之目的，并不意味着赞同其观点或证实其内容的真实性。如涉及作品内容、版权和其它问题，请与本网联系，我们将在第一时间删除内容！ <br />
作者: Mauro Di Pietro<br />
来源： <a href="https://towardsdatascience.com/text-analysis-feature-engineering-with-nlp-502d6ea9225d">https://towardsdatascience.com/text-analysis-feature-engineering-with-nlp-502d6ea9225d</a> </p>
                
                  
                
              
              
  <!-- Add custom comment system integration here -->
  
  
  
  
    <h3 id="__comments">评论</h3>
    <!-- 来必力City版安装代码 -->
    <div id="lv-container" data-id="city" data-uid="MTAyMC81MTg1MC8yODMzMQ==">
      <script type="text/javascript">
      (function(d, s) {
          var j, e = d.getElementsByTagName(s)[0];

          if (typeof LivereTower === 'function') { return; }

          j = d.createElement(s);
          j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
          j.async = true;

          e.parentNode.insertBefore(j, e);
      })(document, 'script');
      </script>
    </div>
  <!-- City版安装代码已完成 -->
  

            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../training-text-model-classification-bert_21Mar13104632238439/" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  上一页
                </span>
                没有模型训练情况下用BERT做文本分类
              </div>
            </div>
          </a>
        
        
          <a href="../using-similarity-sentence-bert-word2vec-_21Apr13202631442339/" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  下一页
                </span>
                如何使用 BERT 和 Word2Vec 计算句子相似性
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright md-footer-copyright-mid">
        
      </div>
      
  <div class="md-footer-social">
    
      
      
        
        
      
      <a href="https://twitter.com/autoadgeek" target="_blank" rel="noopener" title="twitter.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
      </a>
    
      
      
        
        
      
      <a href="https://github.com/autoadgeek" target="_blank" rel="noopener" title="github.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
      </a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tabs", "navigation.instant", "navigation.sections", "navigation.expand", "toc.integrate"], "translations": {"clipboard.copy": "\u590d\u5236", "clipboard.copied": "\u5df2\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}, "search": "../../../../assets/javascripts/workers/search.fe42c31b.min.js", "version": null}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.d892486b.min.js"></script>
      
        <script src="../../../../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>